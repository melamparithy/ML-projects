{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6874874,"sourceType":"datasetVersion","datasetId":3950498},{"sourceId":6956779,"sourceType":"datasetVersion","datasetId":3995882},{"sourceId":6956811,"sourceType":"datasetVersion","datasetId":3995905},{"sourceId":6959436,"sourceType":"datasetVersion","datasetId":3997711}],"dockerImageVersionId":30580,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Implementation of the paper Data2Vis ([link to paper](https://arxiv.org/abs/1804.03126))","metadata":{}},{"cell_type":"code","source":"import tqdm\nimport time\nimport os\nimport random\n\nimport numpy as np \nimport pandas as pd \n\nimport sklearn\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchtext.vocab import build_vocab_from_iterator\nfrom torch.utils.data import TensorDataset, DataLoader\n\n\nimport matplotlib.pyplot as plt\nplt.style.use('default')\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-13T16:58:45.606770Z","iopub.execute_input":"2023-11-13T16:58:45.607704Z","iopub.status.idle":"2023-11-13T16:58:45.615990Z","shell.execute_reply.started":"2023-11-13T16:58:45.607670Z","shell.execute_reply":"2023-11-13T16:58:45.615022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"/kaggle/input/dltpa3-3\"\ndata = dict()\nfor filename in os.listdir(path):\n    with open(path + '/' + filename) as file:\n        data[filename] = list(line.replace('\\n', '').replace('[', '').replace(']', '') for line in file.readlines())\n        \nfor key in data.keys():\n    print(key, ':',len(data[key]))","metadata":{"execution":{"iopub.status.busy":"2023-11-13T16:58:46.611940Z","iopub.execute_input":"2023-11-13T16:58:46.612793Z","iopub.status.idle":"2023-11-13T16:58:48.391882Z","shell.execute_reply.started":"2023-11-13T16:58:46.612763Z","shell.execute_reply":"2023-11-13T16:58:48.391016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seen = set()\nidx = []\nfor j, line in enumerate(data['train.sources']):\n    if line not in seen:\n        seen.add(line)\n        idx.append(j)\nprint(len(seen), len(idx))\ndel seen\n\nx_train = [data['train.sources'][i] for i in idx]\ny_train = [data['train.targets'][i] for i in idx]\nprint(len(x_train), len(y_train))\n\ndef yield_tokens(data_iter, s):\n    for text in data_iter:\n        yield list(text)\n\ns_iter = iter(x_train)\nt_iter = iter(y_train)\nsource_vocab = build_vocab_from_iterator(yield_tokens(s_iter, True), specials=[\"<sos>\", \"<eos>\", \"<pad>\"])\ntarget_vocab = build_vocab_from_iterator(yield_tokens(t_iter, False), specials=[\"<sos>\", \"<eos>\", \"<pad>\"])\nprint(source_vocab.get_stoi(), len(source_vocab.get_stoi()))\nprint(target_vocab.get_stoi(), len(target_vocab.get_stoi()))","metadata":{"execution":{"iopub.status.busy":"2023-11-13T16:58:53.924056Z","iopub.execute_input":"2023-11-13T16:58:53.924432Z","iopub.status.idle":"2023-11-13T16:58:54.735252Z","shell.execute_reply.started":"2023-11-13T16:58:53.924401Z","shell.execute_reply":"2023-11-13T16:58:54.734297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx2chr = target_vocab.get_itos()\nprint(idx2chr)","metadata":{"execution":{"iopub.status.busy":"2023-11-13T16:58:57.449622Z","iopub.execute_input":"2023-11-13T16:58:57.449972Z","iopub.status.idle":"2023-11-13T16:58:57.455472Z","shell.execute_reply.started":"2023-11-13T16:58:57.449946Z","shell.execute_reply":"2023-11-13T16:58:57.454322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def vec2str(vec, itos=idx2chr):\n    string = ''\n    for i in vec:\n        string = string + itos[i]\n    return string","metadata":{"execution":{"iopub.status.busy":"2023-11-13T16:58:58.947657Z","iopub.execute_input":"2023-11-13T16:58:58.948011Z","iopub.status.idle":"2023-11-13T16:58:58.952649Z","shell.execute_reply.started":"2023-11-13T16:58:58.947983Z","shell.execute_reply":"2023-11-13T16:58:58.951756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pad(t, max_len):\n    padding = max_len - len(t) \n    return t + [2]*padding\n\ndef build_array(lines, vocab):\n    vecs = [vocab(list(line)) for line in lines]\n    vecs = [vocab(['<sos>']) + vec + vocab(['<eos>']) for vec in vecs]\n    vecs = [pad(vec, 500) for vec in vecs]\n    return vecs","metadata":{"execution":{"iopub.status.busy":"2023-11-13T16:58:59.796170Z","iopub.execute_input":"2023-11-13T16:58:59.796541Z","iopub.status.idle":"2023-11-13T16:58:59.802333Z","shell.execute_reply.started":"2023-11-13T16:58:59.796511Z","shell.execute_reply":"2023-11-13T16:58:59.801410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xv_train = build_array(x_train, source_vocab)\nyv_train = build_array(y_train, target_vocab)\n\ntraindataset = TensorDataset(torch.tensor(xv_train), torch.tensor(yv_train))\ntrainloader = DataLoader(traindataset, shuffle=True, batch_size=8)\n\ndel xv_train, yv_train","metadata":{"execution":{"iopub.status.busy":"2023-11-13T16:28:01.082908Z","iopub.execute_input":"2023-11-13T16:28:01.083641Z","iopub.status.idle":"2023-11-13T16:28:08.071293Z","shell.execute_reply.started":"2023-11-13T16:28:01.083581Z","shell.execute_reply":"2023-11-13T16:28:08.070284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class encoder(nn.Module):\n    def __init__(self, num_embeddings, embedding_dim, hidden_size, num_layers, dp):\n        super(encoder, self).__init__()\n        self.num_embeddings = num_embeddings\n        self.dropout = nn.Dropout(dp)\n        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n        self.rnn = nn.GRU(input_size=embedding_dim , hidden_size=hidden_size, num_layers=num_layers, bidirectional=True)\n        self.fc = nn.Linear(hidden_size*2, hidden_size)\n    def forward(self, x):\n        x = self.dropout(self.embedding(x))\n        o,h = self.rnn(x)\n        h = torch.tanh(self.fc(torch.cat((h[-2, :, :], h[-1, :, :]), dim=1)))\n        return o, h\n    \nclass attention(nn.Module):\n    def __init__(self, hidden_size):\n        super(attention, self).__init__()\n        self.a = nn.Linear(hidden_size*2 + hidden_size, hidden_size)\n        self.v = nn.Linear(hidden_size, 1, bias=False)\n    def forward(self, d_hidden, e_outputs):\n        b_s = e_outputs.shape[1]\n        seq_len = e_outputs.shape[0]\n        d_hidden = d_hidden.unsqueeze(1).repeat(1, seq_len, 1)\n        e_outputs = e_outputs.permute(1, 0, 2)\n        energy = torch.tanh(self.a(torch.cat((d_hidden, e_outputs),dim=2)))\n        attention = self.v(energy).squeeze(2)\n        return torch.nn.functional.softmax(attention, dim=1)\n        \nclass decoder(nn.Module):\n    def __init__(self, num_embeddings, embedding_dim, hidden_size, num_layers, dp, attention):\n        super(decoder, self).__init__()\n        self.num_embeddings = num_embeddings\n        self.attention = attention\n        self.dropout = nn.Dropout(dp)\n        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n        self.rnn = nn.GRU(hidden_size*2 + embedding_dim, hidden_size)\n        self.fc = nn.Linear(hidden_size*2+hidden_size+embedding_dim, num_embeddings)\n    \n    def forward(self, inp, h, e_outputs):\n        inp = inp.unsqueeze(0)\n        emb = self.dropout(self.embedding(inp))\n        a = self.attention(h, e_outputs)\n        a = a.unsqueeze(1)\n        e_outputs = e_outputs.permute(1, 0, 2)\n        wtd = torch.bmm(a, e_outputs)\n        wtd = wtd.permute(1, 0, 2)\n        rnn_inp = torch.cat((emb, wtd), dim=2)\n        o,h = self.rnn(rnn_inp, h.unsqueeze(0))\n        \n        emb = emb.squeeze(0)\n        o = o.squeeze(0)\n        wtd = wtd.squeeze(0)\n        \n        p = self.fc(torch.cat((o, wtd, emb),dim=1))\n        return p, h.squeeze(0)\n    \nclass seq2seq(nn.Module):\n    def __init__(self, encoder, decoder, device):\n        super(seq2seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.device = device\n    \n    def forward(self, src, trg, trg_len, t_f):\n        outputs = torch.zeros(trg_len, src.shape[1], self.decoder.num_embeddings).to(self.device)\n        e_outputs, hidden = self.encoder(src)\n        inp = trg[0, :]\n        \n        for t in range(1, trg_len):\n            output, hidden = self.decoder(inp, hidden, e_outputs)\n            outputs[t] = output\n            teacher_force = random.random() < t_f\n            top1 = output.argmax(1)\n            inp = trg[t, :] if teacher_force else top1\n        return outputs\n        ","metadata":{"execution":{"iopub.status.busy":"2023-11-13T16:59:03.717036Z","iopub.execute_input":"2023-11-13T16:59:03.717429Z","iopub.status.idle":"2023-11-13T16:59:03.737308Z","shell.execute_reply.started":"2023-11-13T16:59:03.717392Z","shell.execute_reply":"2023-11-13T16:59:03.736249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_src_embeddings = len(source_vocab.get_stoi()) \nnum_trg_embeddings = len(target_vocab.get_stoi())","metadata":{"execution":{"iopub.status.busy":"2023-11-13T16:59:04.795185Z","iopub.execute_input":"2023-11-13T16:59:04.795552Z","iopub.status.idle":"2023-11-13T16:59:04.800166Z","shell.execute_reply.started":"2023-11-13T16:59:04.795522Z","shell.execute_reply":"2023-11-13T16:59:04.799240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_dim = 128\nhidden_size = 128\ndp = 0.5\nnum_layers_enc = 2\nnum_layers_dec = 1\nx,y = next(iter(trainloader))\ne1 = encoder(num_embeddings=num_src_embeddings, embedding_dim=embedding_dim, hidden_size=hidden_size, num_layers=num_layers_enc, dp=dp)\nattn = attention(hidden_size)\nd1 = decoder(num_embeddings=num_trg_embeddings, embedding_dim=embedding_dim, hidden_size=hidden_size, num_layers=num_layers_dec, dp=dp, attention=attn)\nmodel1 = seq2seq(e1, d1, device).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-11-13T11:06:50.842264Z","iopub.execute_input":"2023-11-13T11:06:50.842612Z","iopub.status.idle":"2023-11-13T11:06:55.696498Z","shell.execute_reply.started":"2023-11-13T11:06:50.842579Z","shell.execute_reply":"2023-11-13T11:06:55.695680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def init_weights(m):\n    for name, param in m.named_parameters():\n        if 'weight' in name:\n            nn.init.normal_(param.data, mean=0, std=0.01)\n        else:\n            nn.init.constant_(param.data, 0)\n            \n# model1.apply(init_weights)","metadata":{"execution":{"iopub.status.busy":"2023-11-13T12:34:19.719482Z","iopub.execute_input":"2023-11-13T12:34:19.719780Z","iopub.status.idle":"2023-11-13T12:34:19.729255Z","shell.execute_reply.started":"2023-11-13T12:34:19.719756Z","shell.execute_reply":"2023-11-13T12:34:19.728312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n# print(f'The model has {count_parameters(model1):,} trainable parameters')","metadata":{"execution":{"iopub.status.busy":"2023-11-13T12:34:19.730357Z","iopub.execute_input":"2023-11-13T12:34:19.730646Z","iopub.status.idle":"2023-11-13T12:34:19.744781Z","shell.execute_reply.started":"2023-11-13T12:34:19.730622Z","shell.execute_reply":"2023-11-13T12:34:19.744030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model1.parameters(), lr=1e-3)\ntrg_pad_idx = target_vocab(['<pad>'])[0]\nloss_fn = nn.CrossEntropyLoss(ignore_index = trg_pad_idx)","metadata":{"execution":{"iopub.status.busy":"2023-11-13T11:06:55.722738Z","iopub.execute_input":"2023-11-13T11:06:55.723016Z","iopub.status.idle":"2023-11-13T11:06:55.734782Z","shell.execute_reply.started":"2023-11-13T11:06:55.722990Z","shell.execute_reply":"2023-11-13T11:06:55.733962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, dataloader, optimizer, loss_fn):\n    model.train()\n    epoch_loss = 0\n    t_f = 0.2\n    for x,y in dataloader:\n        x,y = x.permute(1,0).to(model.device), y.permute(1,0).to(model.device)\n        optimizer.zero_grad()\n        output = model(x, y, 500, t_f)\n        output = output[1:].view(-1, output.shape[-1])\n        y = y[1:].reshape(-1)\n        loss = loss_fn(output, y)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n        \n    return epoch_loss/len(dataloader)\n\ndef evaluate(model, dataloader, loss_fn):\n    model.eval()\n    epoch_loss = 0\n    with torch.no_grad():\n        for x,y in dataloader:\n            x,y = x.permute(1,0).to(model.device), y.permute(1,0).to(model.device)\n            output = model(x, y, 500, 0)\n            output = output[1:].view(-1, output.shape[-1])\n            y = y[1:].reshape(-1)\n            loss = loss_fn(output, y)\n            epoch_loss += loss.item()\n    return epoch_loss/len(dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-11-13T12:34:19.745849Z","iopub.execute_input":"2023-11-13T12:34:19.746107Z","iopub.status.idle":"2023-11-13T12:34:19.757861Z","shell.execute_reply.started":"2023-11-13T12:34:19.746084Z","shell.execute_reply":"2023-11-13T12:34:19.756972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 4\nfor i in range(epochs):\n    start = time.time()\n    epoch_loss = train(model1, trainloader, optimizer, loss_fn)\n    end = time.time()\n    print(f'Epoch:{i+1}, Loss:{epoch_loss}, Time:{end-start}s')","metadata":{"execution":{"iopub.status.busy":"2023-11-13T11:09:15.370703Z","iopub.execute_input":"2023-11-13T11:09:15.371558Z","iopub.status.idle":"2023-11-13T12:15:57.201122Z","shell.execute_reply.started":"2023-11-13T11:09:15.371522Z","shell.execute_reply":"2023-11-13T12:15:57.200124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model1.state_dict(), '/kaggle/working/q3-2')","metadata":{"execution":{"iopub.status.busy":"2023-11-13T12:15:57.499569Z","iopub.execute_input":"2023-11-13T12:15:57.499848Z","iopub.status.idle":"2023-11-13T12:15:57.514103Z","shell.execute_reply.started":"2023-11-13T12:15:57.499821Z","shell.execute_reply":"2023-11-13T12:15:57.513365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xv_test = build_array(data['test.sources'], source_vocab)\nyv_test = build_array(data['test.targets'], target_vocab)\n\ntestdataset = TensorDataset(torch.tensor(xv_test), torch.tensor(yv_test))\ntestloader = DataLoader(testdataset, shuffle=True, batch_size=16)\n\ndel xv_test, yv_test","metadata":{"execution":{"iopub.status.busy":"2023-11-13T16:47:53.780283Z","iopub.execute_input":"2023-11-13T16:47:53.780673Z","iopub.status.idle":"2023-11-13T16:48:02.960410Z","shell.execute_reply.started":"2023-11-13T16:47:53.780641Z","shell.execute_reply":"2023-11-13T16:48:02.959339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss = evaluate(model1, testloader, loss_fn)\nprint(test_loss)","metadata":{"execution":{"iopub.status.busy":"2023-11-13T12:16:53.085582Z","iopub.execute_input":"2023-11-13T12:16:53.085980Z","iopub.status.idle":"2023-11-13T12:23:48.372036Z","shell.execute_reply.started":"2023-11-13T12:16:53.085949Z","shell.execute_reply":"2023-11-13T12:23:48.371037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_dim = 128\nhidden_size = 128\ndp = 0.5\nnum_layers_enc = 2\nnum_layers_dec = 1\ne1 = encoder(num_embeddings=num_src_embeddings, embedding_dim=embedding_dim, hidden_size=hidden_size, num_layers=num_layers_enc, dp=dp)\nattn = attention(hidden_size)\nd1 = decoder(num_embeddings=num_trg_embeddings, embedding_dim=embedding_dim, hidden_size=hidden_size, num_layers=num_layers_dec, dp=dp, attention=attn)\nmodel_inf = seq2seq(e1, d1, device).to(device)\nmodel_inf.load_state_dict(torch.load('/kaggle/input/tdlq3-1-1/q3-1.pth'))","metadata":{"execution":{"iopub.status.busy":"2023-11-13T09:49:24.863358Z","iopub.execute_input":"2023-11-13T09:49:24.864056Z","iopub.status.idle":"2023-11-13T09:49:24.896185Z","shell.execute_reply.started":"2023-11-13T09:49:24.864016Z","shell.execute_reply":"2023-11-13T09:49:24.895337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_dim = 256\nhidden_size = 256\ndp = 0.5\nnum_layers_enc = 2\nnum_layers_dec = 1\nx,y = next(iter(trainloader))\ne2 = encoder(num_embeddings=num_src_embeddings, embedding_dim=embedding_dim, hidden_size=hidden_size, num_layers=num_layers_enc, dp=dp)\nattn = attention(hidden_size)\nd2 = decoder(num_embeddings=num_trg_embeddings, embedding_dim=embedding_dim, hidden_size=hidden_size, num_layers=num_layers_dec, dp=dp, attention=attn)\nmodel2 = seq2seq(e2, d2, device).to(device)\n\noptimizer = torch.optim.Adam(model2.parameters(), lr=1e-3)\ntrg_pad_idx = target_vocab(['<pad>'])[0]\nloss_fn = nn.CrossEntropyLoss(ignore_index = trg_pad_idx)\n\nprint(f'The model has {count_parameters(model2):,} trainable parameters')\nmodel2.apply(init_weights)","metadata":{"execution":{"iopub.status.busy":"2023-11-13T12:34:36.773508Z","iopub.execute_input":"2023-11-13T12:34:36.774406Z","iopub.status.idle":"2023-11-13T12:34:41.883156Z","shell.execute_reply.started":"2023-11-13T12:34:36.774369Z","shell.execute_reply":"2023-11-13T12:34:41.882103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 4\nfor i in range(epochs):\n    start = time.time()\n    epoch_loss = train(model2, trainloader, optimizer, loss_fn)\n    end = time.time()\n    print(f'Epoch:{i+1}, Loss:{epoch_loss}, Time:{end-start}s')","metadata":{"execution":{"iopub.status.busy":"2023-11-13T12:34:44.267604Z","iopub.execute_input":"2023-11-13T12:34:44.267960Z","iopub.status.idle":"2023-11-13T15:02:20.276085Z","shell.execute_reply.started":"2023-11-13T12:34:44.267932Z","shell.execute_reply":"2023-11-13T15:02:20.275007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model2.state_dict(), '/kaggle/working/q3-3.pth')","metadata":{"execution":{"iopub.status.busy":"2023-11-13T15:02:20.587985Z","iopub.execute_input":"2023-11-13T15:02:20.588287Z","iopub.status.idle":"2023-11-13T15:02:20.620117Z","shell.execute_reply.started":"2023-11-13T15:02:20.588261Z","shell.execute_reply":"2023-11-13T15:02:20.619194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss = evaluate(model2, testloader, loss_fn)\nprint(test_loss)","metadata":{"execution":{"iopub.status.busy":"2023-11-13T15:09:01.553474Z","iopub.execute_input":"2023-11-13T15:09:01.553881Z","iopub.status.idle":"2023-11-13T15:20:26.522288Z","shell.execute_reply.started":"2023-11-13T15:09:01.553847Z","shell.execute_reply":"2023-11-13T15:20:26.521397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_dim = 256\nhidden_size = 256\ndp = 0.5\nnum_layers_enc = 2\nnum_layers_dec = 1\ne3 = encoder(num_embeddings=num_src_embeddings, embedding_dim=embedding_dim, hidden_size=hidden_size, num_layers=num_layers_enc, dp=dp)\nattn = attention(hidden_size)\nd3 = decoder(num_embeddings=num_trg_embeddings, embedding_dim=embedding_dim, hidden_size=hidden_size, num_layers=num_layers_dec, dp=dp, attention=attn)\nmodel_inf2 = seq2seq(e3, d3, device).to(device)\nmodel_inf2.load_state_dict(torch.load('/kaggle/input/dltp3-3/q3-3.pth'))","metadata":{"execution":{"iopub.status.busy":"2023-11-13T16:59:16.929180Z","iopub.execute_input":"2023-11-13T16:59:16.929561Z","iopub.status.idle":"2023-11-13T16:59:21.748373Z","shell.execute_reply.started":"2023-11-13T16:59:16.929531Z","shell.execute_reply":"2023-11-13T16:59:21.747411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}